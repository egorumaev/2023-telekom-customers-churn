# 2023-telekom-customers-churn
Прогнозирование оттока клиентов оператора связи

# **ПРОЕКТ «Разработка модели машинного обучения для прогнозирования оттока клиентов оператора связи „Ниединогоразрыва.ком‟»**

---

## **Примененные библиотеки и технологии**

* Pandas, Numpy, Matplotlib, Seaborn, Skimpy, Datetime, ydata-profiling, Psutil, Phik, Sklearn, Imblearn, Catboost, Xgboost, LightGBM

* Pipeline, Feature Engineering, RandomizedSearchCV, MinMaxScaler, mutual_info_regression, Mutual Information, OneHotEncoder, OrdinalEncoder, MinMaxScaler, SelectKBest, chi2, VotingClassifier, confusion_matrix, background_gradient

---

## **Цель и задачи проекта**

**Цель проекта**: разработать модель машинного обучения, прогнозирующую возможный отток клиентов.

**Целевое ограничение, по которому оценивается результат выполнения проекта**: значение метрики ROC_AUC лучшей модели на тестовой выборке должно быть **>= 0.85**.

**Целевой прогнозируемый признак** - столбец 'EndDate'.

Для достижения цели были поставлены и решены следующие **задачи**:

 - проведен исследовательский (разведочный) анализ данных, представленных в виде четырех датасетов; 

 - на основе данных датасетов сформированы синтетический целевой признак, обучающий признаки и синтетические обучающие признаки;

 - исследована итоговая таблица с данными; 

 - проведена проверка данных на мультиколинеарность;

 - данные подготовлены для машинного обучения;

 - перед машинным обучением проведена оптимизация загрузки оперативной памяти;

 - сформированы пайплайны для линейной модели и моделей, основанных на решающих деревьях;

 - все модели машинного обучения обучены с помощью кроссвалидации с определением лучших гиперпараметров;

 - модель машинного обучения, показавшая лучшее значение метрики на кроссвалидации, проверена на тестовой выборке;

 - выявлены важнейшие признаки лучшей модели;

 - проведен анализ результатов обучения лучшей модели;

 - подготовлен подробный отчет по проекту.

Решаемая в рамках проекта задача относится к задачам **классификации**.

---

## **Основные результаты**

 **(1)** Анализ личностных характеристик клиентов показал, что более склонны к оттоку люди:

* у которых есть иждивенцы

* имеющие статус пенсионера по возрасту

* не имеющие супруга (супруги)

Пол не влияет на склонность клиента к оттоку. Информация о влиянии возраста в датасетах отсутствует. Целесообразно предусмотреть в будущем сбор сведений о возрасте пользователя.

Особо обратим внимание на высокий уровень оттока среди пенсионеров по возрасту. Объяснить его только естественно-демографическим движением населения с учетом масштаба оттока будет неправильно. По признаку ‘paperless_billing’ доля оттока очень высока среди пользователей, предпочитающих получать счет на оплату в бумажном виде. По всей видимости именно пенсионеры, предпочитающие традиционные формы общения и бумажные документы, посещают клиентские офисы компании. Можно предположить, что молодые продавцы-консультанты не могут на понятном пенсионерам языке объяснить сложные для них вещи. Клиенты пенсионного возраста разочаровываются в операторе связи и прекращают пользоваться его услугами.

Отток среди клиентов, не имеющих супруга (супруги) означает, что речь идет с большей вероятностью о молодежи, которая более склонна экспериментировать, сравнивая качество услуг связи разных операторов, более мобильна при выборе мест учебы и новой работы; предпочитает помесячную оплату, которую легко прекратить и отказаться от услуг связи.

 **(2)** для выполнения проекта была отобрана линейная модель и модели, основанные на решающих деревьях.

**Линейная модель**:

 * LogisticRegression

**Модели, основанные на решающих деревьях**:

 * RandomForestClassifier

 * XGBClassifier

 * HistGradientBoostingClassifier

 * LGBMClassifier

 * CatBoostClassifier с помощью инструментария библиотеки sklearn

 * CatBoostClassifier с помощью инструментария библиотеки catboost

Дополнительно проведено обучение **ансамбля моделей** RandomForestClassifier, XGBClassifier, HistGradientBoostingClassifier, LGBMClassifier, CatBoostClassifier, объединенных с помощью **VotingClassifier**.

 **(3)** Лучшее значение метрики ROC_AUC на обучающей выборке с помощью кроссвалидации получено на модели CatBoostClassifier, обученной с помощью инструментов библиотеки sklearn. **(12)** **Лучшая модель CatBoostClassifier** успешно прошла проверку на тестовой выборке, показав значение **ROC_AUC**, равное **0.918** при целевом ограничении **>= 0.85**.

 **(4)** После серии обучения лучшей модели с разным набором признаков установлено, что сокращение количества признаков до пяти наиболее важных не только не снизило метрику, но, напротив, позволило ее повысить. Благодаря этому количество обучающих признаков модели удалось значительно сократить, обеспечив по-прежнему высокое качество модели. 
